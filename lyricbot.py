from discord.ext import commands
from discord.utils import get
import discord
import requests
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
import html5lib
from datetime import datetime
import re
from wordcloud import WordCloud, ImageColorGenerator
from PIL import Image
import numpy as np
from janome.tokenizer import Tokenizer
from collections import Counter
from itertools import combinations
import networkx as nx
from wordcloud.wordcloud import FONT_PATH
import japanize_matplotlib
import io
import itertools
from janome.analyzer import Analyzer
from janome.tokenfilter import *
# janomeèµ·å‹•
tokenizer = Tokenizer()


'''
requestsã§ã‚½ãƒ¼ã‚¹ç²å¾—
'''
def getsource(url):
    r = requests.get(url)
    # æ•°å€¤æ–‡å­—å‚ç…§ã‚’æ–‡å­—ã«å¤‰æ›ã™ã‚‹å ´åˆã¯html.unescape(r.text)
    return r.content

'''
beautiful soupã‚’ä½¿ã„ã‚„ã™ã„ã‚ˆã†ã«ã‚ªãƒªã‚¸ãƒŠãƒ«é–¢æ•°ã§ãƒã‚¹ãƒˆ(?)
'''

def scrape(res,attrs={},only_sentence='True',name=None,string=None,extract=False):
    soup = BeautifulSoup(res,'html5lib')
    print(soup.prettify() )
    if extract == False:
        elems = soup.find_all(name=name,attrs=attrs,string=string)
    else:
        elems = soup.find_all(name=name,attrs=attrs,string=string).extract()

    if only_sentence == 'False':
        return elems
    else:
        p = re.compile(r"<[^>]*?>")
        res = []
        for elem in elems:
            e = p.sub( "",str(elem) )
            res.append(e)
        return res

'''
å½¢æ…‹ç´ åˆ†æ
'''

def use_janome(content):
    wordlistlist = []
    token_filters = [LowerCaseFilter(),POSKeepFilter(['åè©', 'å‹•è©','å½¢å®¹è©'])] # è‹±å­—ã¯å°æ–‡å­—ã«ã™ã‚‹
    analyzer = Analyzer(tokenizer=tokenizer, token_filters=token_filters)
    for elem in content:
        wordlist = []
        tokens = analyzer.analyze(elem)
        for token in tokens:
            wordlist.append(token.base_form)
        wordlistlist.append(wordlist)
        del wordlist
    print(wordlistlist)
    return wordlistlist

'''
å¼•æ•°ã§ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æ‹¾ãˆã‚‹ã‚ˆã†ã«ã—ã¦ã€å°†æ¥ã‚¸ãƒ£ã‚±ãƒƒãƒˆå†™çœŸã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—ã§ããŸå ´åˆç°¡å˜ã«æ‰±ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
'''
def make_wordcloud(wordlistlist):
    #ç”»åƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

    wordlist =itertools.chain.from_iterable(wordlistlist)
    #wordcloudã®æŒ‡å®š
    wc = WordCloud(background_color="white", max_words=30,random_state=42,prefer_horizontal=1,font_path='/SourceHanSansHW-Regular.otf')
    wc.generate(' '.join(wordlist) )
    #wordcloudã®æå†™
    plt.axis('off')
    plt.imshow(wc,interpolation="bilinear")
    net_img = io.BytesIO()
    plt.savefig(net_img, format='png', bbox_inches="tight")
    net_img.seek(0)
    png_img = discord.File(net_img,filename = f'lyric_co_net.png') 
    net_img.close()
    plt.close()
    return png_img

def make_network(wordlistlist):
    for co_pair in wordlistlist:
        # æ­Œè©ã®è¡Œã”ã¨ã«å˜èªãƒšã‚¢ã‚’ä½œæˆ
        # combinationsã‚’ä½¿ã†ã¨é †ç•ªãŒé•ã†ã ã‘ã®ãƒšã‚¢ã¯é‡è¤‡ã—ãªã„
        # ãŸã ã—ã€åŒå˜èªã®ãƒšã‚¢ã¯å­˜åœ¨ã—ãˆã‚‹ã®ã§setã§ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã™ã‚‹
        pair_all = list(combinations(set(co_pair), 2))
    # å˜èªãƒšã‚¢ã”ã¨ã®å‡ºç¾ç« æ•°
    pair_count = Counter(pair_all)
    # å˜èªã”ã¨ã®å‡ºç¾ç« æ•°
    word_count = Counter()
    for co_pair in wordlistlist:
        word_count += Counter(set(co_pair))
    # å˜èªãƒšã‚¢ã”ã¨ã®jaccardä¿‚æ•°ã‚’è¨ˆç®—
    jaccard_coef = []
    for pair, cnt in pair_count.items():
        jaccard_coef.append(cnt / (word_count[pair[0]] + word_count[pair[1]] - cnt))
    jaccard_dict = {}
    for (pair, cnt), coef in zip(pair_count.items(), jaccard_coef):
        jaccard_dict[pair] = coef
        print(f'ãƒšã‚¢{pair}, å‡ºç¾å›æ•°{cnt}, ä¿‚æ•°{coef}, ãƒ¯ãƒ¼ãƒ‰1å‡ºç¾æ•°{word_count[pair[0]]}, ãƒ¯ãƒ¼ãƒ‰2å‡ºç¾æ•°{word_count[pair[1]]}') 
    print(jaccard_dict)
    # ã‚°ãƒ©ãƒ•ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”Ÿæˆ
    G = nx.Graph()
    for pair, coef in jaccard_dict.items():
        for word in pair:
            G.add_node(word)
        G.add_edge(pair[0], pair[1], weight=coef)

    pr = nx.pagerank(G)
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®æç”»
    plt.figure(figsize=(10,10))
    pos = nx.spring_layout(G, k=0.2)
    nx.draw_networkx(G,pos,
                    node_shape = "s",
                    node_color=list(pr.values()),
                    cmap=plt.cm.rainbow,
                    node_size = 500,
                    edge_color = "gray",
                    font_family = "IPAexGothic")
    net_img = io.BytesIO()
    plt.savefig(net_img, format='png', bbox_inches="tight")
    net_img.seek(0)
    png_img = discord.File(net_img,filename = f'lyric_co_net.png') 
    net_img.close()
    plt.close()
    return png_img        

#ãƒˆãƒ¼ã‚¯ãƒ³å…¥åŠ›
# æ¥ç¶šã«å¿…è¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆ
bot = commands.Bot(command_prefix="~")
# èµ·å‹•&ã‚®ãƒ«ãƒ‰ãƒ­ã‚°ã‚¤ãƒ³æ™‚
@bot.event
async def on_ready():
    print(f'ğŸŸ ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸğŸŸ ã€€â°ãƒ­ã‚°ã‚¤ãƒ³æ—¥æ™‚â°{datetime.now()}')

@bot.command()
async def cloud(ctx, *args):
    '''
    æ­Œè©ã‹ã‚‰ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰
    '''

    res = getsource(f'https://www.google.com/search?q={"%20".join(args)}%20æ­Œè©')
    #Q0HXG
    songname_and_lyric = scrape(res,attrs={"class":"BNeawe tAd8D AP7Wnd"} )
    songname = songname_and_lyric[0]
    lyric = songname_and_lyric[-1].splitlines()
    # ãƒªã‚¹ãƒˆã®ï¼’å€‹ç›®ãŒauthor name
    authorname = scrape(res,attrs={'class':"BNeawe s3v9rd AP7Wnd"})[1]
    print(f'ğŸŒŸ{lyric},{authorname}')
    wordlistlist = use_janome(lyric)
    net_image = make_wordcloud(wordlistlist)
    await ctx.send(file=net_image,content=f'ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå:{authorname}\næ›²å:{songname}\næ­Œè©ã‹ã‚‰ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ä½œã‚Šã¾ã—ãŸã€‚\nhttps://www.google.com/search?q={"%20".join(args)}%20æ­Œè©')


@bot.command()
async def net(ctx, *args):
    '''
    æ­Œè©ã‹ã‚‰å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    '''
    res = getsource(f'https://www.google.com/search?q={"%20".join(args)}%20æ­Œè©')
    songname_and_lyric = scrape(res,attrs={"class":"BNeawe tAd8D AP7Wnd"} )
    songname = songname_and_lyric[0]
    lyric = songname_and_lyric[-1].splitlines()
    # ãƒªã‚¹ãƒˆã®ï¼’å€‹ç›®ãŒauthor name
    authorname = scrape(res,attrs={'class':"BNeawe s3v9rd AP7Wnd"})[1]
    print(f'ğŸŒŸ{lyric},{authorname}')
    wordlistlist = use_janome(lyric)
    net_image = make_network(wordlistlist)
    await ctx.send(file=net_image,content=f'ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå:{authorname}\næ›²å:{songname}\næ­Œè©ã‹ã‚‰å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã‚’ä½œã‚Šã¾ã—ãŸã€‚\nhttps://www.google.com/search?q={"%20".join(args)}%20æ­Œè©')


@bot.command()
async def l(ctx, *args):
    '''
    æ­Œè©ãã®ã‚‚ã®ã‚’è¡¨ç¤º
    '''
    res = getsource(f'https://www.google.com/search?q={"%20".join(args)}%20æ­Œè©')
    songname_and_lyric = scrape(res,attrs={"class":"BNeawe tAd8D AP7Wnd"} )
    songname = songname_and_lyric[0]
    lyric = songname_and_lyric[-1].splitlines()
    # ãƒªã‚¹ãƒˆã®ï¼’å€‹ç›®ãŒauthor name
    authorname = scrape(res,attrs={'class':"BNeawe s3v9rd AP7Wnd"})[1]
    print(f'ğŸŒŸ{lyric},{authorname}')
    lyric1 = list(map(lambda x:x+"\n",lyric))
    print(lyric1)
    embed = discord.Embed(title=f"ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå:{authorname}\næ›²å:{songname}",color=discord.Colour.green(),type = 'rich')
    embed.add_field(name='æ­Œè©',value=f'{"".join(lyric1)}',inline=False)
    embed.add_field(name='URL',value=f'\nhttps://www.google.com/search?q={"%20".join(args)}%20æ­Œè©',inline=False)
    await ctx.send(embed=embed)

@bot.command()
async def snet(ctx, *args):
    '''
    ãŠã¾ã‘ã€€ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ–‡ã‹ã‚‰å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    '''
    print(args)
    wordlistlist = use_janome(args)
    net_image = make_network(wordlistlist)
    await ctx.send(file=net_image,content=f'{ctx.member.name}ã•ã‚“æä¾›ã‚½ãƒ¼ã‚¹ã‹ã‚‰å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã‚’ä½œã‚Šã¾ã—ãŸ')

@bot.command()
async def scloud(ctx, *args):
    '''
    ãŠã¾ã‘ã€€ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ–‡ã‹ã‚‰ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰
    '''
    print(args)
    wordlistlist = use_janome(args)
    net_image = make_wordcloud(wordlistlist)
    await ctx.send(file=net_image,content=f'{ctx.member.name}ã•ã‚“æä¾›ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ä½œã‚Šã¾ã—ãŸ')

bot.run('ODI3ODA3ODU2NjUxNzk2NDkw.YGgaJA.xkmjNtPM3P9kmZ9kNkrjctQIM6k')
# TOKENã«discord bot TOKENã‚’å…¥åŠ›ã™ã‚‹
